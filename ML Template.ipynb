{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#database\n",
    "dataset = pd.read_csv('data1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all null values\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop null values\n",
    "dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#univariate analysis\n",
    "dataset['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute avg age for each gender(both colmns in a db)\n",
    "dataset.groupby('gender')['age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking care of missing data\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(X[:, 2:3])\n",
    "X[:,2:3] = imputer.transform(X[:, 2:3])\n",
    "\n",
    "\n",
    "imputer1 = SimpleImputer(missing_values=np.nan, strategy='constant',fill_value='C')\n",
    "imputer1 = imputer1.fit(X[:, 6:])\n",
    "X[:,6:] = imputer1.transform(X[:, 6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking care of missing data\n",
    "df['string column name'].fillna(df['string column name'].mode().values[0], inplace = True)\n",
    "df['numeric column name'].fillna(df['numeric column name'].mean(), inplace = True)\n",
    "df['column name'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding categorical data\n",
    "dataset['sex']=dataset['sex'].replace(['female','male','other'],[0,1,2])\n",
    "dataset['smoking']=dataset['smoking'].replace(['never','quit','yes'],[0,1,2])\n",
    "dataset['working']=dataset['working'].replace(['home','never','stopped','travel critical','travel non critical'],[1,0,2,3,4])\n",
    "dataset['income']=dataset['income'].replace(['blank','gov','high','med','low'],[0,4,3,2,1])\n",
    "dataset['blood_type']=dataset['blood_type'].replace(['unknown','abn','abp','an','ap','bn','bp','on','op'],[0,1,2,3,4,5,6,7,8])\n",
    "dataset['insurance']=dataset['insurance'].replace(['no','yes'],[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding categorical data\n",
    "def convert_words_to_int(word):\n",
    "        word_dict={\"one\":1,\"two\":2}\n",
    "        return word_dict[word]\n",
    "X[\"expereince\"]=X[\"expereince\"].apply(lamda x: convert_words_to_int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding categorical data\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "ct = ColumnTransformer([('one_hot_encoder', OneHotEncoder(), [0,4,5,9])],remainder='passthrough')\n",
    "X= np.array(ct.fit_transform(X), dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avoiding the dummy variable trap\n",
    "X=X[:,[0,1,3,4,5,6,8,9,11,12,13,15,16,17,18,19,20,21,22,23,24,25,26,27]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting best features\n",
    "#apply SelectKBest class to extract top 10 best features\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "fs = SelectKBest(score_func=chi2, k='all')\n",
    "fs.fit(X_train, y_train)\n",
    "X_fs = fs.transform(X_train)\n",
    "X_fs = fs.transform(X_train)\n",
    "for i in range(len(fs.scores_)):\n",
    "\tprint('Feature %d: %f' % (i, fs.scores_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting best features\n",
    "import statsmodels.api as sm\n",
    "X=np.append(arr=np.ones((50,1)).astype(int),values=X,axis=1)\n",
    "#50 here is number of rows in X,change that acc\n",
    "X_opt = np.array(X[:, [0, 1, 2, 3, 4, 5]], dtype=float)\n",
    "#remove umimp indep variables\n",
    "regressor_OLS=sm.OLS(endog=y,exog=X_opt).fit()\n",
    "regressor_OLS.summary()\n",
    "#select rown with p>0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting best features \n",
    "X_train=X_train[:,[0,1,3,4]]\n",
    "X_test=X_test[:,[0,1,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining X and y\n",
    "X1=dataset.iloc[:,[0,1,2,3,4,5,6,9,10,12,18,19,20,21,26,32]].values\n",
    "y1=dataset.iloc[:,33].values\n",
    "X2=dataset.iloc[:,0:33].values\n",
    "y2=dataset.iloc[:,34].values\n",
    "\n",
    "X = data.drop(['Species'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size = 0.25,random_state=42)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size = 0.25,random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor=LinearRegression()\n",
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting\n",
    "y_pred1 = regressor1.predict(X_test1)\n",
    "y_pred2 = regressor2.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(acc)\n",
    "\n",
    "#Accuracy(dont use this)\n",
    "print(classifier.score(X_train,y_train))\n",
    "print(classifier.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual input\n",
    "new_input=np.array([gender,age,height,weight,income,smoking,alcohol,contacts,totalpeople,working,masks,symptoms,contactsinfected,asthma,lung,healthworker])\n",
    "new_input1=new_input.reshape(1,-1)\n",
    "new_output = regressor.predict(new_input1)\n",
    "print(\"\\nRisk of getting covid-19\", new_output,\"%\")\n",
    "OR\n",
    "regressor.predict([[gender,age,height]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if used feature scaling, then manual input-\n",
    "new_output=sc_x.inverse_transform(regressor.predict(sc_x.transform(np.array([6.5]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save into csv file\n",
    "kaggle_data = pd.DataFrame({'PassengerId':dataset2.PassengerId, 'Survived':y_pred}).set_index('PassengerId')\n",
    "kaggle_data.to_csv('sub1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a pickle file\n",
    "import pickle\n",
    "filename = 'finalized_model'\n",
    "pickle.dump(regressor, open(filename, 'wb'))\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "#better way for pickle\n",
    "import pickle\n",
    "pickle_out=open(\"classifier.pkl\",\"wb\")\n",
    "pickle.dump(classifier,pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the pickle file later\n",
    "pickle_in=open(\"classifier.pkl\",\"rb\")\n",
    "classifier=pickle.load(pickle_in)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
